{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python & Data - Week 10\n",
    "\n",
    "Web Scraping - Beautiful Soup\n",
    "\n",
    "[打包下載](../week10.zip)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 步驟\n",
    "\n",
    "1. 發現需要截取的 html tag 和 class / id 名\n",
    "2. 使用 Beautiful Soup 獲取內容"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 使用 Beautiful Soup 獲取內容"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 安裝 Beautiful Soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mDEPRECATION: Configuring installation scheme with distutils config files is deprecated and will no longer work in the near future. If you are using a Homebrew or Linuxbrew Python, please see discussion at https://github.com/Homebrew/homebrew-core/issues/76621\u001b[0m\n",
      "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.9/site-packages (4.10.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.9/site-packages (from beautifulsoup4) (2.3.1)\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 22.0.4 is available.\n",
      "You should consider upgrading via the '/usr/local/opt/python@3.9/bin/python3.9 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install beautifulsoup4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 基本用法\n",
    "\n",
    "\\#1 使用 `BeautifulSoup(page.content, \"html.parser\")` 初始化功能，page.content 是 requests 返回的原始內容 (bytes)  \n",
    "\\#2 使用 soup.find_all 找尋所有 `<a>` 的標籤  \n",
    "\\#3 印出每個 link 的內容  \n",
    "\\#4 使用 link['href'] 判斷 tag 的屬性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "返回舊版網頁\n",
      "中文\n",
      "English\n",
      "\n",
      "首頁\n",
      "最新資訊\n",
      "培正簡介\n",
      "校徽及校歌\n",
      "學校簡介\n",
      "校務簡報\n",
      "校曆資訊\n",
      "校園地圖\n",
      "基督教教育\n",
      "團體組織\n",
      "網址精選\n",
      "聯絡我們\n",
      "校園即時影像\n",
      "入學及收費資訊\n",
      "eClass\n",
      "EVI\n",
      "圖書館\n",
      "中華文化館\n",
      "全部\n",
      "學校動態\n",
      "學生獎項\n",
      "其他資訊\n",
      "媒體報導\n",
      "「世界記憶學術中心」交流活動獲益良多\n",
      "詳細\n",
      "「職安健吉祥物」填色比賽表現出色\n",
      "詳細\n",
      "英國劍橋大學入學考試消息\n",
      "https://shorturl.at/fgmEH\n",
      "詳細\n",
      "學界乒乓球單打賽獲五冠\n",
      "詳細\n",
      "全澳中學生衛星概念徵集比賽共兩隊獲獎\n",
      "詳細\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "下一頁 >\n",
      "\n",
      "\n",
      "共建群體免疫屏障\n",
      "關注本校的 YouTube\n",
      "關注本校的 Facebook\n",
      "關注本校的 Instagram\n",
      "特別資訊RSS\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "URL = \"http://www.puiching.edu.mo/news\"\n",
    "page = requests.get(URL)\n",
    "\n",
    "soup = BeautifulSoup(page.content, \"html.parser\") #1\n",
    "links = soup.find_all(\"a\") #2\n",
    "\n",
    "for link in links:\n",
    "    print(link.text) #3\n",
    "    #if link['href'].startswith('/news'): #4\n",
    "    #    print(link.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### 使用 tag 及 href 屬性不足以篩選出需要的內容\n",
    "\n",
    "![Filtering Results](./images/bs_tag_and_href.png)\n",
    "\n",
    "#### Tag, Attribute...?\n",
    "\n",
    "![Tag, Attribute and Text](./images/tag_attr_text.png)\n",
    "\n",
    "#### HTML DOM Tree\n",
    "\n",
    "![DOM Tree](./images/pic_htmltree.gif)\n",
    "\n",
    "來源: [HTML DOM](https://www.w3schools.com/js/js_htmldom.asp)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 使用多重方法解析出需要的內容\n",
    "\n",
    "![HTML Child Nodes](./images/html_child_nodes.png)\n",
    "\n",
    "步驟:\n",
    "\n",
    "1. 先取得 div.news-item-container 的部分\n",
    "2. 再針對每個 div 解析出 a, span.date, .news-content 等資料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "「世界記憶學術中心」交流活動獲益良多\n",
      "/news/view/3339\n",
      "「職安健吉祥物」填色比賽表現出色\n",
      "/news/view/3338\n",
      "英國劍橋大學入學考試消息\n",
      "/news/view/3337\n",
      "學界乒乓球單打賽獲五冠\n",
      "/news/view/3327\n",
      "全澳中學生衛星概念徵集比賽共兩隊獲獎\n",
      "/news/view/3334\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "URL = \"http://www.puiching.edu.mo/news\"\n",
    "page = requests.get(URL)\n",
    "\n",
    "soup = BeautifulSoup(page.content, \"html.parser\")\n",
    "containers = soup.find_all(class_=\"news-item-container\")\n",
    "\n",
    "for news_container in containers:\n",
    "    title_element = news_container.find(\"a\") # 針對每個 news_container 找出 a (只有一個)\n",
    "    print(title_element.text) # 印出 <a> 的文字內容\n",
    "    print(title_element['href']) # 印出 a 的 href 屬性"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 下一步...\n",
    "\n",
    "1. 找出日期\n",
    "2. 繼續挖掘詳細頁內容\n",
    "3. 繼續挖掘下一頁內容"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Beautiful Soup Cheatsheet\n",
    "\n",
    "1. 獲取 BS 實體\n",
    "\n",
    "`soup = BeautifulSoup(text, \"html.parser\")`\n",
    "> text 是 html 內容，可以通過讀取檔案或 requests.get 取得\n",
    "> \"html.parser\" 是其中一種 parser 類型\n",
    "\n",
    "2. 找出所有指定 tag\n",
    "\n",
    "`elements = soup.find_all(tag)`\n",
    "> tag 是 HTML tag 的類型，例如：div, a, span 等\n",
    "> elements 是 iterable 類型，可以使用 for 取得所有內容\n",
    "\n",
    "3. 指定某個 class 的 tag\n",
    "\n",
    "`elements = soup.find_all(\"div\", class_=\"news-item-container\")`  \n",
    "`element = soup.find(\"span\", class_=\"date\")`\n",
    "> find_all 找出所有匹配的內容，find 找出第一個匹配的內容\n",
    "> 使用 class_ 收窄結果的範圍到某一個 class 名稱\n",
    "\n",
    "4. 指定某個 id 的元素\n",
    "\n",
    "`element = soup.find(id=\"page-nav\")`\n",
    "> id 指定了某個 id=\"page-nav\" 的 tag\n",
    "> 理論上每個 id 在 html 是唯一的，所以用 find 找出第一個匹配的元素\n",
    "\n",
    "5. 元素的文字內容\n",
    "\n",
    "`element.text`\n",
    "> 使用 .text 返回文字內容，如元素中有 html 碼會被去除\n",
    "\n",
    "6. 元素的 Attribute 內容\n",
    "\n",
    "`element[attr]`\n",
    "> attr 是屬性的名稱，例如 `element['href']` 可找出 href 屬性的內容"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
