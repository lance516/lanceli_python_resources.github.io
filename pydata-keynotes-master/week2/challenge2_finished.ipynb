{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenge 2\n",
    "\n",
    "在指定的資料夾找尋內容相同的檔案，列印出哪兩個檔案是相同的。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "import time\n",
    "import hashlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hash Function\n",
    "\n",
    "提供的 hash function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = hashlib.sha1()\n",
    "\n",
    "def hash_file(filename):\n",
    "   \"\"\"\"This function returns the SHA-1 hash\n",
    "   of the file passed into it\"\"\"\n",
    "\n",
    "   # make a hash object\n",
    "   h = hashlib.sha1()\n",
    "\n",
    "   # open file for reading in binary mode\n",
    "   with open(filename,'rb') as file:\n",
    "       # loop till the end of the file\n",
    "       chunk = 0\n",
    "       while chunk != b'':\n",
    "           # read only 1024 bytes at a time\n",
    "           chunk = file.read(1024)\n",
    "           h.update(chunk)\n",
    "\n",
    "   # return the hex representation of digest\n",
    "   return h.hexdigest()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 檢查資料夾下的重覆檔案\n",
    "\n",
    "* 使用 os.listdir 列出每個檔案\n",
    "    * 針對檔案，計算檔案的 hash\n",
    "    * 檢查 hash 是否已存在於 file_hashes (key)  \n",
    "        ➡️ 如已存在，則印出兩個檔案的名稱\n",
    "    * 將 hash (key) 和檔案名稱 (value) 記錄到 file_hashes\n",
    "    * 重覆步驟\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/file1_copy.txt and data/file1.txt is the same\n"
     ]
    }
   ],
   "source": [
    "# Setup variables\n",
    "# \n",
    "dir = \"data\"\n",
    "file_hashes = {}\n",
    "for filename in os.listdir(dir):\n",
    "    f = os.path.join(dir, filename)\n",
    "    \n",
    "    if os.path.isfile(f):\n",
    "        hash = hash_file(f)\n",
    "        if hash in file_hashes:\n",
    "            print(f'{f} and {file_hashes[hash]} is the same')\n",
    "        else:\n",
    "            file_hashes[hash] = f\n",
    "    elif os.path.isdir(f):\n",
    "        pass # We do nothing with the folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "結果應為：\n",
    "\n",
    "`data/file1_copy.txt and data/file1.txt is the same`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sub_folder 應如何處理?\n",
    "\n",
    "使用 Recrusion 處理:\n",
    "\n",
    "* 將剛才的程式寫成 function\n",
    "* 在列出檔案時，檢查目前 filename 是一個檔案還是資料夾\n",
    "    * 如果是檔案，如常做檢查\n",
    "    * 如果是資料㚒，則交給 check_duplicates 去檢查"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/file1_copy.txt and data/file1.txt is the same\n",
      "data/sub_folder/file4.txt and data/file2.txt is the same\n"
     ]
    }
   ],
   "source": [
    "my_file_hashes = {}\n",
    "def check_duplicates(dir):\n",
    "    for filename in os.listdir(dir):\n",
    "        f = os.path.join(dir, filename)\n",
    "        \n",
    "        if os.path.isfile(f):\n",
    "            hash = hash_file(f)\n",
    "            if hash in my_file_hashes:\n",
    "                print(f'{f} and {my_file_hashes[hash]} is the same')\n",
    "            else:\n",
    "                my_file_hashes[hash] = f\n",
    "        elif os.path.isdir(f):\n",
    "            check_duplicates(f)\n",
    "\n",
    "# Starting point\n",
    "check_duplicates(dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "結果應為：\n",
    "\n",
    "```\n",
    "data/file1_copy.txt and data/file1.txt is the same\n",
    "data/sub_folder/file4.txt and data/file2.txt is the same\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 如何避免無限循環 (或檢查太多層數)?\n",
    "\n",
    "在 check_duplicates 加入 max_depth 參數控制 recursive 次數\n",
    "\n",
    "```python\n",
    "def check_duplicates(dir, max_depth = 0)\n",
    "    for filename in os.listdir(dir):\n",
    "        f = os.path.join(dir, filename)\n",
    "        \n",
    "        if os.path.isfile(f):\n",
    "            pass # ...\n",
    "        elif os.path.isdir(f) and max_depth > 1:\n",
    "            check_duplicates(f, max_depth - 1)\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
